using System;
using Nemerle;
using Nemerle.Collections;
using Nemerle.Text;
using Nemerle.Utility;
using Nemerle.Compiler;
using Nemerle.Compiler.Parsetree;
using Nemerle.Compiler.Parsetree.PExpr;
using Nemerle.Compiler.Token;

namespace Nemerle.Peg
{
  public class CriticalUnexpectedException : Exception  { }

  /// <summary>
  /// Description of Parsing.
  /// </summary>
  module Parsing
  {
    public ParseRules(typer : Typer, startRule : NameRef, rules : PExpr) : Grammar
    {
      match (rules)
      { // Match grammar { ... } RawToken macro (defined above)
      | MacroCall(name, _ns, [SyntaxElement.RawToken(LooseGroup(BracesGroup(tokens, _)))]) => // Name * NamespaceTree.Node * list [SyntaxElement]
        if (name.Id != "grammar")
          ReportCriticalUnexpected(rules, "grammar { ... }")
        else
          Parsing.ParseEbnf(typer, tokens, Grammar(startRule))
      | rule            => ReportCriticalUnexpected(rule, "grammar { ... }")
      }
    }

    public ParseEbnf(typer : Typer, token : Token, grammar : Grammar) : Grammar
    {
      #region Grammar rules
      // Rule            = RuleName ((':' Type)? '=' OrderedChoice)?
      // OrderedChoice   = Sequence ('/' Sequence)*
      // Sequence        = PredicateRule+
      // PredicateRule   = ('!' / '&')? CardinalityRule
      // CardinalityRule = SimpleRule ('?' / '+' / '*')?
      // SimpleRule      = FailureRecovery '(' OrderedChoice ')', RuleName '{' OrderedChoice '}' / RuleName / Range / Char / String / '(' OrderedChoice ')' / Empty
      // RuleName        = Token.Identifier(name)
      // Char            = Token.CharLiteral
      // String          = Token.StringLiteral
      // Range           = Token.SquareGroup(LooseGroup(CharLiteral, Operator(".."), CharLiteral))
      // Eq              = Token.Operator("=")
      // Empty           = Token.Identifier("Empty")
      #endregion Grammar rules
      #region Parse helpers

      def parseZeroOrMany(
        tok            : Token,
        parseDelemiter : Token -> Token,
        parseParser    : Token -> Rule * Token
      )
        : list[Rule] * Token
      {
        def tok1 = match (tok)
          {
            | LooseGroup(child) => child
            | _ => tok
          };

        def (seq, nextTok) = parseParser(tok1);

        def loop(tok, acc) : list[Rule] * Token
        {
          def nextTok1 = if (parseDelemiter == null) tok else parseDelemiter(tok);

          if (nextTok1 == null)
            (acc, tok) // predicate not matched
          else
          {
            def (seq, nextTok2) = parseParser(nextTok1);
            if (seq == null)           (acc, nextTok2)
            else if (nextTok2 == null) (seq :: acc, null)
            else                       loop(nextTok2, seq :: acc)
          }
        }

        if (seq == null)
          ([], tok)
        else if (nextTok == null)
          ([seq], nextTok)
        else
        {
          def (res, nextTok) = loop(nextTok, [seq]);
          (res.Rev(), nextTok)
        }
      }

      def parseOneOrMany(
        tok : Token,
        parseDelemiter : Token -> Token,
        parseParser    : Token -> Rule * Token,
        expected : string
      ) : list[Rule] * Token
      {
        def result = parseZeroOrMany(tok, parseDelemiter, parseParser);

        when (result[0].IsEmpty)
          _ = ReportCriticalUnexpected(tok, expected);

        result
      }

      #endregion Parse helpers
      #region Rules parsing

      def parser = MainParser(typer.Env);

      // Range           = Token.SquareGroup(LooseGroup(CharLiteral, Operator(".."), CharLiteral))
      def parseRange(tok : Token) : Rule * Token
      {
        | SquareGroup(entry) =>
          def parseEntry(entry : Token, set : RangeSet) : RangeSet
          {
            match (entry)
            {
              | LooseGroup(CharLiteral
                where (Next = Operator where (name = "..", Next = CharLiteral as ch2)) as ch1) =>

                def resSet = set.AddRange(ch1.value, ch2.value);
                if (entry.Next == null) resSet
                else                    parseEntry(entry.Next, resSet)

              | CharLiteral(ch) =>
                def resSet = set.AddRange(ch, ch);
                if (entry.Next == null) resSet
                else                    parseEntry(entry.Next, resSet)

              | LooseGroup(Identifier(name))
              | Identifier(name) =>
                match(RangeSets.GetRangeSetByName(name))
                {
                  | Some(range) =>
                    def resSet = set.Sum(range);
                    if (entry.Next == null) resSet
                    else                    parseEntry(entry.Next, resSet)
                  | _ => ReportCriticalUnexpected(entry, "valid unicode class name")
                }

              | _ => ReportCriticalUnexpected(entry, "startChar .. endChar or char")
            }
          }

          def set = parseEntry(entry, RangeSet());
          (Rule.Chars(tok.Location, [set]), tok.Next)

        | _ => ReportCriticalUnexpected(tok, "[ ... ]")
      }
      // SimpleRule      = FailureRecovery '(' Identifier,  OrderedChoice ')', RuleName '{' OrderedChoice '}' / RuleName / Range / Char / String / '(' OrderedChoice ')' / Empty
      and parseSimpleRule(tok : Token) : Rule * Token
      {
        | SquareGroup as group        => (parseRange(group)[0], group.Next)
        | Token.Operator("%")         => (Rule.Cut(tok.Location), tok.Next)
        | Identifier(name)            =>
          def ruleName = NameRef(tok.Location, name);

          match (tok.Next)
          {
            | BracesGroup(LooseGroup(IntegerLiteral), _)
                                   => (Rule.Call(tok.Location, ruleName, 0), tok.Next)
            | BracesGroup as group => (Rule.Scope(tok.Location + group.Location, ruleName, parseOrderedChoice(group.Child)[0]), group.Next)
            | Operator(":") as tok =>
              match (tok.Next)
              {
                | IntegerLiteral as tok =>
                  match (tok.lit.AsInt)
                  {
                    | Some(bp) => (Rule.Call(tok.Location, ruleName, bp), tok.Next)
                    | _        => ReportCriticalUnexpected(tok, "integer-literal")
                  }
                | tok => ReportCriticalUnexpected(tok, "integer-literal")
              }
            | _                    => (Rule.Call(tok.Location, ruleName, 0), tok.Next)
          }

        | RoundGroup as group         =>
          def (rule, nextToken) = parseOrderedChoice(group.Child);

          if (nextToken == null)
            (rule, group.Next)
          else
            ReportCriticalUnexpected(nextToken, "',' or ')'");

        | StringLiteral(value = str)  => (Rule.Chars(tok.Location, str.Map(ch => RangeSet().AddRange(ch, ch))), tok.Next)
        | CharLiteral(ch)             => (Rule.Chars(tok.Location, [RangeSet().AddRange(ch, ch)]), tok.Next)
        | null                        => (Rule.Sequence([]), null)
        | _                           => (null, tok)
      }
      // CardinalityRule = SimpleRule ('?' / '+' / '*')?
      and parseCardinalityRule(tok : Token) : Rule * Token
      {
        def (innerRule, nextTok2) = parseSimpleRule(tok);

        match (nextTok2)
        {
          | Operator("?") => (Rule.RepeatMinMax(nextTok2.Location, 0, 1, innerRule), nextTok2.Next)
          | Operator("+") => (Rule.RepeatMin(nextTok2.Location, 1, innerRule),       nextTok2.Next)
          | Operator("*") => (Rule.RepeatMin(nextTok2.Location, 0, innerRule),       nextTok2.Next)
          | BracesGroup(LooseGroup(tok), _) =>
            def getIntValue(tok)
            {
              | IntegerLiteral(lit) when !lit.is_negative =>
                match (lit.AsInt)
                {
                  | Some(value) => value
                  | _ => ReportCriticalUnexpected(tok, "positive integer literal")
                }

              | _ => ReportCriticalUnexpected(tok, "positive integer literal")
            }

            def first = getIntValue(tok);

            match (tok.Next)
            {
              | null  => (Rule.RepeatMinMax(nextTok2.Location, first, first, innerRule), nextTok2.Next)
              | Comma as next when next.Next is Token.Keyword("_") => // {n, _} - n or more
                when (next.Next.Next != null)
                  ReportUnexpected(next.Next, "EOF");

                (Rule.RepeatMin(nextTok2.Location, first, innerRule), nextTok2.Next)

              | Comma as next => // {n, m} - from n to m
                def second = getIntValue(next.Next);

                when (second < first)
                  ReportUnexpected(next.Next, $"a integer literal which greater or equal to $first");

                (Rule.RepeatMinMax(nextTok2.Location, first, second, innerRule), nextTok2.Next)

              | _ => (innerRule, nextTok2)
            }

          | _             => (innerRule, nextTok2)
        }
      }
      // PredicateRule   = ('!' / '&')? CardinalityRule
      and parsePredicateRule(tok : Token) : Rule * Token
      {
        def (rule, nextTok1) =
          match (tok)
          {
           | Operator("!") => (Rule.Not : Location * Rule -> Rule, tok.Next)
           | Operator("&") => (Rule.And : Location * Rule -> Rule, tok.Next)
           | _             => (null,     tok)
          };

        def (innerRule, nextTok2) = parseCardinalityRule(nextTok1);
        if (rule == null) (innerRule,       nextTok2)
        else              (rule(tok.Location + innerRule.Location, innerRule), nextTok2)
      }
      // Sequence        = PredicateRule+
      and parseSequence(tok : Token) : Rule * Token
      {
        def  (seqs, nextTok) = parseOneOrMany(tok, null, parsePredicateRule, "PredicateRule");
        def loc = if (seqs.IsEmpty) tok.Location else tok.Location + seqs.Last.Location;
        (Rule.Sequence(loc, seqs), nextTok)
      }
      // OrderedChoice   = Sequence ( '/' Sequence)*
      and parseOrderedChoice(tok : Token) : Rule * Token
      {
        def parseSlash(tok : Token) : Token
        {
          | Operator("/") =>
            if (tok.Next == null) ReportCriticalUnexpected(tok, "rule")
            else tok.Next

          | _             => null
        }

        def  (seqs, nextTok) = parseOneOrMany(tok, parseSlash, parseSequence, "sequence");
        def loc = if (seqs.IsEmpty) tok.Location else tok.Location + seqs.Last.Location;
        (Rule.Choice(loc, seqs), nextTok)
      }
      and parceRecoveryAttribute(tok : Token, makeAttr : (Location * NameRef * Rule * Rule) -> RuleAttribute) : RuleAttribute * Token
      {
        match (tok.Next)
        {
          | RoundGroup as group =>
            match (group.Child)
            {
              | LooseGroup(Identifier(handlerName) as id) as looseGroup =>
                if (looseGroup.Next is LooseGroup)
                {
                  when (looseGroup.Next == null)
                    _ = ReportCriticalUnexpected(looseGroup, "recovery-handler-name, stopper-rule, rule-to-skip");
                  when (looseGroup.Next.Next == null)
                    _ = ReportCriticalUnexpected(looseGroup.Next, "recovery-handler-name, stopper-rule, rule-to-skip");

                  def (stopperRule, _) = parseOrderedChoice(looseGroup.Next);
                  def (skipRule, _)    = parseOrderedChoice(looseGroup.Next.Next);
                  def location         = tok.Location + group.Location;
                  def name             = NameRef(id.Location, handlerName);
                  def attr             = makeAttr(location, name, stopperRule, skipRule);
                  (attr, group.Next)
                }
                else
                  ReportCriticalUnexpected(group, "(recovery-handler-name, stopper-rule, rule-to-skip)")

              | _ => ReportCriticalUnexpected(group, "(recovery-handler-name, stopper-rule, rule-to-skip)")
            }
          | null => ReportCriticalUnexpected(tok, "FailureRecovery(recovery-handler-name, stopper-rule, rule-to-skip)")
          | x => ReportCriticalUnexpected(x, "(recovery-handler-name, stopper-rule, rule-to-skip)")
        }
      }
      // Rule            = RuleName ((':' Type)? '=' OrderedChoice)?
      def parseRule(tok : Token, ruleId : int) : RuleDefinition
      {
        def getName(tok : Token) : NameRef
        {
          match (tok.Next)
          {
            | Identifier(name) as id  =>
              when (id.Next != null)
                ReportUnexpected(id.Next, "nothing");

              NameRef(id.Location, name)

            | null                    => ReportCriticalUnexpected(tok, "rule-name");
            | x                       => ReportCriticalUnexpected(x, "rule-name");
          }
        }
        def parseExtensible(tok : Token, expected : string) : RuleAttribute
        {
          //assert2(false);
          def (expr, nextToken) = parser.ParseExpr(tok, TokenStoppers.All);

          when (nextToken != null)
            ReportUnexpected(nextToken, "nothing");

          match (expr)
          {
            | <[ Extensible($(name : name)) ]> => RuleAttribute.Extensible(tok.Location, NameRef(name.Location, name.Id))
            | <[ Extends($ruleName) ]>         => RuleAttribute.Extends(tok.Location, ruleName)
            | _ => ReportCriticalUnexpected(tok, expected);
          }
        }
        def straightenLooseGroup(tok2 : Token)
        {
          match (tok2, tok2.Next)
          {
            | (LooseGroup(child1) as g1, LooseGroup(child2) as g2) when !(g1.SeparatorToken is Semicolon) =>
              def getLastTok(tok3 : Token)
              {
                if (tok3.Next == null)
                  tok3
                else
                  getLastTok(tok3.Next)
              }
              def lastTok = getLastTok(child1);
              lastTok.Next = child2; // append
              def newLoose = LooseGroup(g1.Location + g2.Location, child1, g2.SeparatorToken);
              newLoose.Next = g2.Next;
              tok.Next = g2.Next;
              straightenLooseGroup(newLoose)

            | _ => tok2
          }
        }
        match (straightenLooseGroup(tok))
        {
          | LooseGroup(child) =>
            def parseAttrs(tok : Token)
            {
              | SquareGroup(child) =>

                def parseAttr(g : Token) : RuleAttribute * Token
                {
                  | LooseGroup(tok) =>
                    match (tok)
                    {
                      | Identifier("Inline")            => (RuleAttribute.Inline(g.Location), g.Next)
                      | Identifier("InlineAllSubrules") => (RuleAttribute.InlineAllSubrules(g.Location), g.Next)
                      | Identifier("OmitLocation")      => (RuleAttribute.OmitLocation(g.Location), g.Next)
                      | Identifier("Export")            => (RuleAttribute.Export(g.Location), g.Next)
                      | Identifier("Extends")           => (parseExtensible(g, "Extends(rule-name)"), g.Next)
                      | Identifier("Extensible")        => (parseExtensible(g, "Extensible(ambiguity-handler-name)"), g.Next)
                      | Operator("%")                   => parceRecoveryAttribute(tok, RuleAttribute.Cut);
                      | Identifier("FailureRecovery")   => parceRecoveryAttribute(tok, RuleAttribute.Recovery);
                      | Operator("<")   => (RuleAttribute.PrecedenceLesserThan (g.Location, getName(tok)), g.Next)
                      | Operator(">")   => (RuleAttribute.PrecedenceGreaterThan(g.Location, getName(tok)), g.Next)
                      | Operator("==")  => (RuleAttribute.PrecedenceEqualsTo   (g.Location, getName(tok)), g.Next)
                      | _ => ReportCriticalUnexpected(g, RuleAttribute.GetUsages())
                    }

                  | _ => ReportCriticalUnexpected(tok, RuleAttribute.GetUsages())
                }
                def parseAttrs(currTok : Token, attrs = [])
                {
                  if (currTok == null) attrs.Reverse()
                  else
                  {
                    def (attr, next) = parseAttr(currTok);
                    parseAttrs(next, attr :: attrs)
                  }
                }

                (tok.Next, parseAttrs(child, []))

              | _ => (tok, [])
            }
            def (tok2, ruleAttrs) = parseAttrs(child);

            //assert2(!_debug);

            def (expr, nextToken) = parser.ParseExpr(if (tok2 is Identifier) LooseGroup(tok2)
                                                     else tok2,
                                                     TokenStoppers.All);
            def (id, ruleType) =
              match (expr)
              {
                | <[ $name : $ty ]>  => (name, RuleDefinitionType.Typed(BindFixedType(ty, typer)))
                | <[ $name is $ty ]> => (name, RuleDefinitionType.Extention(NameRef(ty.Location, ty.ToString())))
                | Ref as name        => (name, RuleDefinitionType.None())
                | _                  => ReportCriticalUnexpected(tok2, "rule-name (':' return-type)?");
              };

            def name = NameRef(id.Location, id.ToString());

            if (nextToken == null)
              RuleDefinition(id.Location, ruleId, name, ruleType, ruleAttrs, None());
            else if (!(nextToken is Operator("=")))
              ReportCriticalUnexpected(nextToken, "('=' rule-body)? ';'");
            else if (nextToken.Next == null)
              ReportCriticalUnexpected(nextToken, "('=' rule-body)? ';'");
            else
            {
              def (rule, nextTok) = parseOrderedChoice(nextToken.Next);

              when (nextTok != null)
                _ = ReportUnexpected(nextTok, "EOF");
              RuleDefinition(id.Location + rule.Location, ruleId, name, ruleType, ruleAttrs, Some(rule));
            }

          | _ => ReportCriticalUnexpected(token, <# [Attributes] RuleName (("extends" RuleRef / ':' Type)? '=' OrderedChoice)?;#>)
        }
      }
      def parseGramar(grammar : Grammar, token : Token) : Grammar
      {
        //assert2(!token.ToString().Contains("using"));
        def grammar2 =
          match (token)
          {
            | LooseGroup(Keyword("using") as u) =>
              when (u.Next == null)
                _ = ReportCriticalUnexpected(u, "using perser-type;");

              def (expr, nextToken) = parser.ParseExpr(u.Next, TokenStoppers.None);

              when (nextToken != null)
                ReportUnexpected(nextToken, "nothing");

              match (expr)
              {
                | <[ $(alias : name) = $parserType ]> =>
                  grammar.Add(GrammarRef.Alias(u.Location,
                    NameRef(alias.Location, alias.Id), typer.BindFixedType(parserType)))

                | _ => grammar.Add(GrammarRef.Ref(u.Location, typer.BindFixedType(expr)))
              }

            | _ =>
              def ruleDefinition = parseRule(token, grammar.Count);

              if (ruleDefinition.Rule == null)
                grammar
              else
                grammar.Add(ruleDefinition)
          };

        if (token.Next == null)
          grammar2
        else
          parseGramar(grammar2, token.Next)
      }

      #endregion Rules parsing

      parseGramar(grammar, token)
    }

    mutable _debug : bool = false;

    #region Error handling

    ReportCriticalUnexpected[T](token : Token, expected : string) : T
    {
      ReportUnexpected(token, expected);
      throw CriticalUnexpectedException()
    }

    ReportUnexpected(token : Token, expected : string) : void
    {
      assert2(!_debug);
      Message.Error(token.Location, $"expected «$expected» but found «$token» ($(token.GetType().Name))");
    }

    ReportUnexpected(expr : PExpr, expected : string) : void
    {
      assert2(!_debug);
      Message.Error(expr.Location, $"expected $expected but found $expr ($(expr.GetType().Name))");
    }

    ReportCriticalUnexpected[T](expr : PExpr, expected : string) : T
    {
      ReportUnexpected(expr, expected);
      throw CriticalUnexpectedException()
    }

    #endregion

    #region Helpers

    BindFixedType(id : PExpr, typer : Typer) : RuleType.NType
    {
      RuleType.NType(id.Location, typer.BindFixedType(id))
    }

    #endregion
  }
}
